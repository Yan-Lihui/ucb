{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Lab 5: Skip-gram",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yan-Lihui/ucb/blob/master/Lab_5_Skip_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDlU-kLCKDVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME = \"Lihui Yan\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW9zL4V6KDVc",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9a0ec075584699a44c46933457b0a8ba",
          "grade": false,
          "grade_id": "cell-a910b376742d04c0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ECD5r2hFKDVd",
        "colab_type": "text"
      },
      "source": [
        "# Lab 5: Skip Gram\n",
        "\n",
        "**Please read the following instructions very carefully**\n",
        "\n",
        "## Working on the assignment / FAQs\n",
        "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments) \n",
        "- The type of question and the points they carry are indicated in each question cell\n",
        "- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n",
        "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
        "- You can delete the `raise NotImplementedError()`\n",
        "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n",
        "- That's about it. Happy coding!\n",
        "\n",
        "\n",
        "Available software:\n",
        " - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n",
        " - Sklearn’s  TSNE module in case you use TSNE to reduce dimension (optional)\n",
        " - Python’s Matplotlib (optional)\n",
        "\n",
        "_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a09a0bf3042da711c4bf843e9b4a4189",
          "grade": false,
          "grade_id": "cell-bf780e597c0216c8",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Vsocwry-KDVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "d102af47-9018-4ea5-bfd9-6c353ddfa58d"
      },
      "source": [
        "!pip install gensim\n",
        "!wget -nc https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz \n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import gensim\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.37)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.37 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.37)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "File ‘GoogleNews-vectors-negative300.bin.gz’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "47031c66b74746d23ccc5e8369446a4b",
          "grade": false,
          "grade_id": "cell-3f89500615a0096f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZF74G9bDKDVh",
        "colab_type": "text"
      },
      "source": [
        "### **Q1 (1 point)** \n",
        "Find the cosine similarity between the following word pairs\n",
        "\n",
        "- (France, England)\n",
        "- (smaller, bigger)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4d52dda406c3d8cd5e37d29755f0fb12",
          "grade": false,
          "grade_id": "cell-fbbe575f8f5a6368",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "SZD5ZaMvKDVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "3ebfec37-e989-418d-b667-419f31237bcf"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "word_vectors = model.wv\n",
        "word_vectors.vocab\n",
        "word_pairs = [      \n",
        "              ('France','England'),\n",
        "              ('smaller','bigger'),\n",
        "              ('England','London'), \n",
        "              ('France','Rocket'),\n",
        "              ('big','bigger')\n",
        "            ]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "569aa8b664a41d901bf7b0a5e23e9930",
          "grade": true,
          "grade_id": "cell-929d59ed5d67f618",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "tFUPLSK7KDVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "9209bf31-71ab-4ed4-e348-440d87939275"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "for pair in word_pairs:\n",
        "    print(model.similarity(pair[0], pair[1]))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.39804944\n",
            "0.7302272\n",
            "0.43992856\n",
            "0.07114174\n",
            "0.68423855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a7f270405ddf9ecbffde36e6c096b818",
          "grade": false,
          "grade_id": "cell-ccd6618b4fac3715",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZcqpWCjJKDVs",
        "colab_type": "text"
      },
      "source": [
        "### **Q2 (1 point)** \n",
        "Write an expression to extract the vector representations of the words: \n",
        "\n",
        "- France\n",
        "- England\n",
        "- smaller\n",
        "- bigger\n",
        "- rocket\n",
        "- big\n",
        "\n",
        "Get only the first 5 elements for each vector representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "6b3cecb268eb9440c446cd3de984b7f6",
          "grade": false,
          "grade_id": "cell-00f3d05abb28aa23",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "6pzKlLyjKDVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n",
        "\n",
        "words = ['France','England','smaller','bigger','rocket','big']\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "401940f859774b3c1ec48338fa15682e",
          "grade": true,
          "grade_id": "cell-6f34229370fa873f",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "Hkj2ROGTKDVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "610d2228-4129-4020-ef79-af9c89a338d7"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "for word in words:\n",
        "  print(model[word][:5])\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n",
            "[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n",
            "[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n",
            "[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n",
            "[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n",
            "[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ac8b42811c924e7988f17b9dbd3f71ef",
          "grade": false,
          "grade_id": "cell-4ad44071d3785409",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "2UBnMwiXKDVy",
        "colab_type": "text"
      },
      "source": [
        "### **Q3 (1 point)** \n",
        "Find the euclidean distances between the word pairs : \n",
        "\n",
        "- (France, England)\n",
        "- (smaller, bigger)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "a771483fbb59086604eb84bcc7c7f0ad",
          "grade": false,
          "grade_id": "cell-3aba86afc0ebd8a8",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "zQGd-YVoKDV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "fa646871-7a71-4003-e334-411d50ffc117"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "def eucliDist(A,B):\n",
        "    return np.sqrt(sum(np.power((A - B), 2)))\n",
        "X = np.array(['France','smaller','England','France','big'])\n",
        "Y = np.array(['England','bigger','London','Rocket','bigger'])\n",
        "print(eucliDist(X,Y))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UFuncTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9c7011475315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'France'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'smaller'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'England'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'France'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'big'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'England'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bigger'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'London'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Rocket'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bigger'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meucliDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-9c7011475315>\u001b[0m in \u001b[0;36meucliDist\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meucliDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'France'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'smaller'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'England'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'France'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'big'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'England'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bigger'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'London'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Rocket'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bigger'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U7'), dtype('<U7')) -> dtype('<U7')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "17796eb5de342e8f8e841aa137a2c41c",
          "grade": true,
          "grade_id": "cell-15ffa50b82de21ad",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "HsSg0l2UKDV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is an autograded cell, do not edit / delete\n",
        "print(eu_dist1)\n",
        "print(eu_dist2)\n",
        "print(eu_dist3)\n",
        "print(eu_dist4)\n",
        "print(eu_dist5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "afc0e843c7545e2df83448feda9f28f5",
          "grade": false,
          "grade_id": "cell-7cd8b9b67386376d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "XvO2iU7QKDWA",
        "colab_type": "text"
      },
      "source": [
        "### **Q4 (1 point)**\n",
        "Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n",
        "- (King - Man + Queen)\n",
        "- (bigger - big + small)\n",
        "- (man + programmer - woman)\n",
        "- (waiting - wait + run)\n",
        "- (Texas + Milwaukee – Wisconsin)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "50ef096feb166865434fe2fca3d41f99",
          "grade": false,
          "grade_id": "cell-b72201968c5fd1ec",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "jCxWmA1eKDWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "closest1 = 0\n",
        "closest2 = 0\n",
        "closest3 = 0\n",
        "closest4 = 0\n",
        "closest5 = 0\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f9c5ff502264f29d2632c6387f92686a",
          "grade": true,
          "grade_id": "cell-b69718ab0e1470bc",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "io9elfD8KDWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(closest1)\n",
        "print(closest2)\n",
        "print(closest3)\n",
        "print(closest4)\n",
        "print(closest5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "6432058d78f4fa52224c48a3b3e71d0d",
          "grade": false,
          "grade_id": "cell-73dca0e2072fef91",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "erUu4u71KDWJ",
        "colab_type": "text"
      },
      "source": [
        "### **Q5 (3 points)**\n",
        "Using the vectors for the words in the Google News dataset, explore the semantic representation of these words through K-means clustering and explain your findings.\n",
        "\n",
        "*Note : Since there are ~3Mil words in the vocabulary, you can downsample it to ~20-30k randomly selected words*\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "7ecef46689f11d4d0a6fed72e049235f",
          "grade": true,
          "grade_id": "cell-80b177848b8b0212",
          "locked": false,
          "points": 3,
          "schema_version": 1,
          "solution": true
        },
        "id": "M3jN02fOKDWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0467b27a0f59504cbb62b851a002386f",
          "grade": false,
          "grade_id": "cell-5b2a5e8ff6c74323",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "rmdtLoHkKDWR",
        "colab_type": "text"
      },
      "source": [
        "### **Q6 (1 point)**\n",
        "What loss function does the skipgram model use and briefly describe what this function is minimizing.\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "774aef2c5bf8ef9d92e3489d1cd80390",
          "grade": true,
          "grade_id": "cell-90cc4b2c0ae8e2c2",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "SyOASYXOKDWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c14f6069f64cc86ab6e384d28df270d8",
          "grade": false,
          "grade_id": "cell-74a177caaabb5009",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "dbpuJx9CKDWV",
        "colab_type": "text"
      },
      "source": [
        "### **Bonus Question (1 point)** \n",
        "Find at least 2 interesting word vec combinations like the ones given in Q5\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "c2d42b5327f4b020c7e1706506dd5ce9",
          "grade": true,
          "grade_id": "cell-7351297993d72e83",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "pQM8C_T7KDWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}